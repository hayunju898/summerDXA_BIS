{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585fca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv('/Users/yunjuha/Desktop/SROP/DXA_BIS_Project/narrowed down list/narrowed_transformed_data.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fb453",
   "metadata": {},
   "source": [
    "# Lasso Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff02f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: DXA Model, Handgrip Strength (Arms)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.08902150854450393\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.8057440379110141\n",
      "R-squared: 0.3687208887155251\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.5324461818143136\n",
      "R-squared: 0.5211126585873147\n",
      "      Feature  Importance\n",
      "3    RA1PRSEX   -0.402187\n",
      "1     RA4DABM    0.248962\n",
      "8      RA4P1A    0.074148\n",
      "0     RA4DALM    0.000000\n",
      "2     RA4DAFM   -0.000000\n",
      "4     RA1PF7A   -0.000000\n",
      "5   Age_40_50    0.000000\n",
      "6   Age_51_61   -0.000000\n",
      "7  Age_61plus   -0.000000\n",
      "9   RA4DLR3MD    0.000000\n"
     ]
    }
   ],
   "source": [
    "#DXA model, handgrip strength (Arms)\n",
    "\n",
    "print(\"MLR: DXA Model, Handgrip Strength (Arms)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4DALM', 'RA4DABM', 'RA4DAFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD']\n",
    "X = df[columns]\n",
    "y = df['tRA4IMaxGrip']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30e32ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: DXA Model, Handgrip Strength (TB)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.026560877829466867\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.7994562521150469\n",
      "R-squared: 0.37364720233680404\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.5234229958359314\n",
      "R-squared: 0.5292282009498037\n",
      "       Feature  Importance\n",
      "3     RA1PRSEX   -0.463062\n",
      "0      RA4IALM    0.167635\n",
      "8       RA4P1A    0.154175\n",
      "2     RA4DTBFM   -0.111588\n",
      "9    RA4DLR3MD    0.043877\n",
      "5    Age_40_50    0.019857\n",
      "6    Age_51_61   -0.016805\n",
      "4      RA1PF7A   -0.014649\n",
      "1     RA4DTBBM    0.000000\n",
      "7   Age_61plus   -0.000000\n",
      "10   RA4DLFNMD    0.000000\n",
      "11    RA4DLSMD   -0.000000\n"
     ]
    }
   ],
   "source": [
    "#DXA model, handgrip strength (TB)\n",
    "\n",
    "print(\"Lasso: DXA Model, Handgrip Strength (TB)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IALM', 'RA4DTBBM', 'RA4DTBFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4DLFNMD', 'RA4DLSMD']\n",
    "X = df[columns]\n",
    "y = df['tRA4IMaxGrip']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0b9794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: DXA Model, Jump Power (Legs)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.0031257158496882354\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.031784446934849185\n",
      "R-squared: 0.7778120618017147\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.034491751002571604\n",
      "R-squared: 0.7045677170042773\n",
      "      Feature  Importance\n",
      "0     RA4ILLM    0.230873\n",
      "7  Age_61plus   -0.106555\n",
      "2     RA4DLFM   -0.097609\n",
      "3    RA1PRSEX   -0.044297\n",
      "9   RA4DLFNMD    0.043985\n",
      "6   Age_51_61   -0.032467\n",
      "5   Age_40_50   -0.010648\n",
      "4     RA1PF7A   -0.007053\n",
      "1     RA4DLBM    0.000000\n",
      "8      RA4P1A    0.000000\n"
     ]
    }
   ],
   "source": [
    "#DXA model, jump power (Legs)\n",
    "\n",
    "print(\"MLR: DXA Model, Jump Power (Legs)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4ILLM', 'RA4DLBM', 'RA4DLFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLFNMD']\n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8088b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: DXA Model, Jump Power (TB)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.0041320124001153384\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.03063773190504295\n",
      "R-squared: 0.7858281285495767\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.03006382195190246\n",
      "R-squared: 0.7424942690162275\n",
      "       Feature  Importance\n",
      "0      RA4IALM    0.252593\n",
      "2     RA4DTBFM   -0.107874\n",
      "7   Age_61plus   -0.073140\n",
      "11    RA4DLSMD   -0.064418\n",
      "10   RA4DLFNMD    0.062543\n",
      "1     RA4DTBBM    0.025896\n",
      "9    RA4DLR3MD    0.025528\n",
      "6    Age_51_61   -0.020998\n",
      "4      RA1PF7A   -0.018153\n",
      "3     RA1PRSEX   -0.001397\n",
      "5    Age_40_50   -0.000000\n",
      "8       RA4P1A   -0.000000\n"
     ]
    }
   ],
   "source": [
    "#DXA model, jump power (TB)\n",
    "\n",
    "print(\"Lasso: DXA Model, Jump Power (TB)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IALM', 'RA4DTBBM', 'RA4DTBFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4DLFNMD', 'RA4DLSMD']\n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659ce410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: BIS Model, Handgrip Strength\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.06734150657750829\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.7854498261319686\n",
      "R-squared: 0.3846208660945817\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.5267236488731454\n",
      "R-squared: 0.5262595610911591\n",
      "       Feature  Importance\n",
      "10    RA1PRSEX   -0.463386\n",
      "15      RA4P1A    0.201971\n",
      "7   RA4IRESINC   -0.133330\n",
      "3     RA4DTBFM   -0.008380\n",
      "0     RA4IMECF    0.000000\n",
      "1     RA4IMICF    0.000000\n",
      "2     RA4IMFFM    0.000000\n",
      "4     RA4IRES0   -0.000000\n",
      "5   RA4IRESINF   -0.000000\n",
      "6   RA4IRESEXC   -0.000000\n",
      "8    RA4IFCHAR   -0.000000\n",
      "9     RA4IMCAP    0.000000\n",
      "11     RA1PF7A   -0.000000\n",
      "12   Age_40_50    0.000000\n",
      "13   Age_51_61   -0.000000\n",
      "14  Age_61plus   -0.000000\n"
     ]
    }
   ],
   "source": [
    "#BIS Model, handgrip strength\n",
    "\n",
    "print(\"Lasso: BIS Model, Handgrip Strength\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IMECF', 'RA4IMICF', 'RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A']\n",
    "X = df[columns]\n",
    "y = df['tRA4IMaxGrip']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38844562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: BIS Model, Jump Power\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.00023101297000831605\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.030708695722430537\n",
      "R-squared: 0.785332058748383\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.03021443820527312\n",
      "R-squared: 0.7412041952363768\n",
      "       Feature  Importance\n",
      "1     RA4IMICF    0.630075\n",
      "0     RA4IMECF   -0.397771\n",
      "9     RA4IMCAP   -0.223159\n",
      "10    RA1PRSEX   -0.188537\n",
      "5   RA4IRESINF    0.103823\n",
      "8    RA4IFCHAR   -0.089501\n",
      "14  Age_61plus   -0.076885\n",
      "6   RA4IRESEXC   -0.074774\n",
      "3     RA4DTBFM   -0.065637\n",
      "7   RA4IRESINC   -0.057627\n",
      "13   Age_51_61   -0.033408\n",
      "4     RA4IRES0   -0.032187\n",
      "12   Age_40_50   -0.027423\n",
      "15      RA4P1A    0.026145\n",
      "11     RA1PF7A    0.007058\n",
      "2     RA4IMFFM    0.000000\n"
     ]
    }
   ],
   "source": [
    "#BIS Model, jumppower\n",
    "\n",
    "print(\"Lasso: BIS Model, Jump Power\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IMECF', 'RA4IMICF', 'RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A']\n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ef05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: Combo Models, Handgrip Strength (Arms)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.04229242874389499\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.7680800159231048\n",
      "R-squared: 0.3982296523044804\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.5061607882306464\n",
      "R-squared: 0.5447540005317261\n",
      "       Feature  Importance\n",
      "3     RA1PRSEX   -0.368550\n",
      "1      RA4DABM    0.212095\n",
      "8       RA4P1A    0.136006\n",
      "17  RA4IRESINC   -0.115391\n",
      "13    RA4DTBFM   -0.054737\n",
      "5    Age_40_50    0.007846\n",
      "4      RA1PF7A   -0.005901\n",
      "0      RA4DALM    0.000000\n",
      "18   RA4IFCHAR    0.000000\n",
      "16  RA4IRESEXC   -0.000000\n",
      "15  RA4IRESINF   -0.000000\n",
      "14    RA4IRES0   -0.000000\n",
      "10    RA4IMECF    0.000000\n",
      "12    RA4IMFFM    0.000000\n",
      "11    RA4IMICF    0.000000\n",
      "9    RA4DLR3MD    0.000000\n",
      "7   Age_61plus   -0.000000\n",
      "6    Age_51_61   -0.000000\n",
      "2      RA4DAFM   -0.000000\n",
      "19    RA4IMCAP    0.000000\n"
     ]
    }
   ],
   "source": [
    "#Combo Models, handgrip strength (Arms)\n",
    "print(\"MLR: Combo Models, Handgrip Strength (Arms)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4DALM', 'RA4DABM', 'RA4DAFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4IMECF', 'RA4IMICF', 'RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP']\n",
    "X = df[columns]\n",
    "y = df['tRA4IMaxGrip']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e89b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: Combo Models, Handgrip Strength (TB)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.04229242874389499\n",
      "Best Max Iterations: 10000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.775998599619775\n",
      "R-squared: 0.3920256517243138\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.5169995439524833\n",
      "R-squared: 0.5350055168555633\n",
      "       Feature  Importance\n",
      "2     RA1PRSEX   -0.446021\n",
      "7       RA4P1A    0.225807\n",
      "18  RA4IRESINC   -0.158719\n",
      "14    RA4DTBFM   -0.047405\n",
      "8    RA4DLR3MD    0.015574\n",
      "4    Age_40_50    0.003199\n",
      "0      RA4IALM    0.000000\n",
      "13    RA4IMFFM    0.000000\n",
      "19   RA4IFCHAR    0.000000\n",
      "17  RA4IRESEXC   -0.000000\n",
      "16  RA4IRESINF   -0.000000\n",
      "15    RA4IRES0   -0.000000\n",
      "10    RA4DLSMD    0.000000\n",
      "12    RA4IMICF    0.000000\n",
      "11    RA4IMECF    0.000000\n",
      "1     RA4DTBBM    0.000000\n",
      "9    RA4DLFNMD    0.000000\n",
      "6   Age_61plus   -0.000000\n",
      "5    Age_51_61   -0.000000\n",
      "3      RA1PF7A   -0.000000\n",
      "20    RA4IMCAP    0.000000\n"
     ]
    }
   ],
   "source": [
    "#Combo Models, handgrip strength (TB)\n",
    "\n",
    "print(\"Lasso: Combo Models, Handgrip Strength (TB)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IALM', 'RA4DTBBM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4DLFNMD', 'RA4DLSMD', 'RA4IMECF', 'RA4IMICF','RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP'] \n",
    "X = df[columns]\n",
    "y = df['tRA4IMaxGrip']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [10000, 20000, 30000, 50000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa441a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR: Combo Models, Jump Power (Legs)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.0001\n",
      "Best Max Iterations: 100000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.0272855204692876\n",
      "R-squared: 0.8092616320125097\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.02483479054249781\n",
      "R-squared: 0.7872825051084335\n",
      "       Feature  Importance\n",
      "15  RA4IRESINF    0.735387\n",
      "16  RA4IRESEXC   -0.511309\n",
      "10    RA4IMECF   -0.477401\n",
      "11    RA4IMICF    0.382957\n",
      "17  RA4IRESINC   -0.307531\n",
      "0      RA4ILLM    0.291955\n",
      "3     RA1PRSEX   -0.168906\n",
      "19    RA4IMCAP   -0.119236\n",
      "2      RA4DLFM   -0.061662\n",
      "9    RA4DLFNMD    0.060938\n",
      "1      RA4DLBM   -0.058924\n",
      "8       RA4P1A    0.051931\n",
      "7   Age_61plus   -0.049331\n",
      "4      RA1PF7A   -0.031362\n",
      "18   RA4IFCHAR   -0.028974\n",
      "6    Age_51_61   -0.018622\n",
      "13    RA4DTBFM   -0.010084\n",
      "5    Age_40_50   -0.004647\n",
      "12    RA4IMFFM    0.000000\n",
      "14    RA4IRES0   -0.000000\n"
     ]
    }
   ],
   "source": [
    "#Combo Models, jumppower (Legs)\n",
    "\n",
    "print(\"MLR: Combo Models, Jump Power (Legs)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4ILLM', 'RA4DLBM', 'RA4DLFM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLFNMD', 'RA4IMECF', 'RA4IMICF', 'RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP']\n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [100000, 200000, 300000, 500000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bad639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: Combo Models, Jump Power (TB)\n",
      "\n",
      "TRANSFORMED\n",
      "Best Alpha: 0.0001\n",
      "Best Max Iterations: 100000\n",
      "\n",
      "TEST Set Metrics:\n",
      "Mean Squared Error: 0.026975864371782433\n",
      "R-squared: 0.8114262709000835\n",
      "\n",
      "TRAINING Set Metrics:\n",
      "Mean Squared Error: 0.023802768535850196\n",
      "R-squared: 0.7961220858389971\n",
      "       Feature  Importance\n",
      "16  RA4IRESINF    0.558539\n",
      "17  RA4IRESEXC   -0.378355\n",
      "11    RA4IMECF   -0.372867\n",
      "0      RA4IALM    0.304621\n",
      "18  RA4IRESINC   -0.268781\n",
      "12    RA4IMICF    0.225653\n",
      "2     RA1PRSEX   -0.089887\n",
      "20    RA4IMCAP   -0.071651\n",
      "14    RA4DTBFM   -0.053495\n",
      "9    RA4DLFNMD    0.052204\n",
      "6   Age_61plus   -0.045836\n",
      "10    RA4DLSMD   -0.043420\n",
      "3      RA1PF7A   -0.041051\n",
      "7       RA4P1A    0.038741\n",
      "1     RA4DTBBM    0.021806\n",
      "5    Age_51_61   -0.017769\n",
      "8    RA4DLR3MD    0.015352\n",
      "19   RA4IFCHAR   -0.008570\n",
      "4    Age_40_50   -0.001387\n",
      "13    RA4IMFFM    0.000000\n",
      "15    RA4IRES0   -0.000000\n"
     ]
    }
   ],
   "source": [
    "#Combo Models, jumppower (TB)\n",
    "\n",
    "print(\"Lasso: Combo Models, Jump Power (TB)\")\n",
    "\n",
    "print(\"\\nTRANSFORMED\")\n",
    "columns = ['RA4IALM', 'RA4DTBBM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4DLFNMD', 'RA4DLSMD', 'RA4IMECF', 'RA4IMICF','RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP'] \n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "#dividing into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "max_iters = [100000, 200000, 300000, 500000]\n",
    "param_grid = {'alpha': alphas, 'max_iter': max_iters}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search results\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Max Iterations:\", best_max_iter)\n",
    "\n",
    "# Retrain the model with the entire training set using the best hyperparameters\n",
    "best_lasso_model = Lasso(alpha=best_alpha, max_iter=best_max_iter)\n",
    "best_lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_lasso_model.predict(X_test_scaled)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nTEST Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Evaluate the model on the train set\n",
    "y_pred_train = best_lasso_model.predict(X_train_scaled)\n",
    "mse_train = metrics.mean_squared_error(y_train, y_pred_train)\n",
    "r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nTRAINING Set Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)\n",
    "\n",
    "# Get the feature importance (coefficients) from the Lasso model\n",
    "feature_importance = best_lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame to associate each feature with its importance value\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the features based on their importance (absolute value of coefficients) in descending order\n",
    "importance_df = importance_df.reindex(importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6e9eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.03\n",
      "0.035\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     active_coefficients\u001b[38;5;241m.\u001b[39mappend(active_percentage)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Plot the errors and active coefficients\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m fig, ax1 \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m     44\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(sparsity_levels, train_errors, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(sparsity_levels, val_errors, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "columns = ['RA4IALM', 'RA4DTBBM', 'RA1PRSEX', 'RA1PF7A', 'Age_40_50', 'Age_51_61', 'Age_61plus', 'RA4P1A', 'RA4DLR3MD', 'RA4DLFNMD', 'RA4DLSMD', 'RA4IMECF', 'RA4IMICF','RA4IMFFM', 'RA4DTBFM', 'RA4IRES0', 'RA4IRESINF', 'RA4IRESEXC', 'RA4IRESINC', 'RA4IFCHAR', 'RA4IMCAP'] \n",
    "X = df[columns]\n",
    "y = df['tjumppownums']\n",
    "\n",
    "# Splitting the data into train, test, and validation sets (80 train, 10 test, 10 validation)\n",
    "X_train, X_testval, y_train, y_testval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_testval, y_testval, test_size=0.5, random_state=42)\n",
    "\n",
    "sparsity_levels = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035]\n",
    "#sparsity_levels = [0.0001, 0.0002, 0.0004, 0.0008, 0.0016]\n",
    "\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "active_coefficients = []\n",
    "\n",
    "for sparsity in sparsity_levels:\n",
    "    print(sparsity)\n",
    "    \n",
    "    #fit lasso\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    results = model.fit_regularized(alpha=sparsity, L1_wt=1)\n",
    "\n",
    "    #predicted for training and validation\n",
    "    y_train_pred = results.predict(X_train)\n",
    "    y_val_pred = results.predict(X_val)\n",
    "\n",
    "    #mse\n",
    "    train_error = np.mean((y_train_pred - y_train) ** 2)\n",
    "    val_error = np.mean((y_val_pred - y_val) ** 2)\n",
    "\n",
    "    train_errors.append(train_error)\n",
    "    val_errors.append(val_error)\n",
    "\n",
    "    #count of the non-zero coefficients\n",
    "    non_zero_coeffs = np.sum(results.params != 0)\n",
    "\n",
    "    #percentage of active coefficients\n",
    "    active_percentage = non_zero_coeffs / len(X.columns) * 100\n",
    "    active_coefficients.append(active_percentage)\n",
    "\n",
    "# Plot the errors and active coefficients\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(sparsity_levels, train_errors, label='Training error')\n",
    "ax1.plot(sparsity_levels, val_errors, label='Validation error')\n",
    "ax1.set_xlabel('Sparsity')\n",
    "ax1.set_ylabel('Mean Squared Error')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(sparsity_levels, active_coefficients, label='Active Coefficients', color='green')\n",
    "ax2.set_ylabel('Active Coefficients (%)')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
